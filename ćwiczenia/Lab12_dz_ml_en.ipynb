{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.4.2"
    },
    "colab": {
      "name": "Lab12_dz_ml_en.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-1q7-q9zsEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%pylab inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv6PavFizsEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.datasets\n",
        "import sklearn.linear_model\n",
        "import sklearn.model_selection\n",
        "import sklearn.metrics\n",
        "import sklearn.multiclass\n",
        "import sklearn.preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiwrPv4LzsEc",
        "colab_type": "text"
      },
      "source": [
        "# Machine learning\n",
        "\n",
        "Several most relevant modules of the `scikit-learn` library are imported above. The API is documented on the following website:\n",
        "\n",
        "http://scikit-learn.org/stable/modules/classes.html\n",
        "\n",
        "It is also worth checking out:\n",
        "\n",
        "http://scikit-learn.org/stable/user_guide.html\n",
        "\n",
        "Let's first load and study the digits database stored in the method `sklearn.datasets.load_digits()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkPvXaF0zsEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMxrzbR1zsEe",
        "colab_type": "text"
      },
      "source": [
        "Load the database again with the argument `return_X_y` set to `True`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOrJX46vzsEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43QHv0WHzsEh",
        "colab_type": "text"
      },
      "source": [
        "Draw a few sample images from the database:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6U343l0zsEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNcZjpfmzsEk",
        "colab_type": "text"
      },
      "source": [
        "## Spliting the data to test and train\n",
        "\n",
        "This is easily achievable using the`sklearn.model_selection.train_test_split()` method. The `test_size` argument allows choosing the ratio of the data used for testing.\n",
        "\n",
        "Divide the dataset randomly: 90% for training and 10% testing. Draw the histogram of classes in the test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD00itiszsEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4rDrbyCzsEn",
        "colab_type": "text"
      },
      "source": [
        "### Stratification\n",
        "\n",
        "Scikit-learn allows for easy stratification of the data allowing for an equal representation of classes within the dataset. Use the `sklearn.model_selection.StratifiedShuffleSplit` class to split the data similarly as above. This class can be used to split the data several times, but for this example we need only to set `n_splits` to 1. The result of the `split` method of this class is a generator (normally used within loops), but you can use the built-in `next` method to retreive the first (and only) split.\n",
        "\n",
        "Generate a stratified split of data (just like above) and draw its test class histogram:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vaZev_pzsEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POKc6sfpzsEp",
        "colab_type": "text"
      },
      "source": [
        "## Classification\n",
        "\n",
        "We will use a very simple linear model called \"logistic regression\". The `sklearn.linear_model.LogisticRegression` class contains many initialization parametrs, but we'll use the default for now. \n",
        "\n",
        "Use the `fit` method with the training and then `predict` method with test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG4zbMM4zsEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWe9TIanzsEr",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "The `sklearn.metrics` module contains many evaluation methods, but it's important to understand exactly what they do. Some work only for specific classification methods, so it's a good idea to read the documentation if something goes wrong.\n",
        "\n",
        "The simplest most verstaile metric is `sklearn.metrics.accuracy_score`. Calculate it for the above result.\n",
        "\n",
        "You can also try computing precision/recall/F1, however note they work for binary classification only. They can nvertheless be computed by estimating each class individually and averaging the result. Change the parameter `average` to `micro`, `macro` or `weighted`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVdT1ReCzsEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzWKOXndzsEu",
        "colab_type": "text"
      },
      "source": [
        "#### Confusion matrix\n",
        "\n",
        "A confusion matrix is a very useful tool for analyzing errors. Compute and draw it using `sklearn.metrics.confusion_matrix`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogm-G-mUzsEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duEVhwHpzsEw",
        "colab_type": "text"
      },
      "source": [
        "## Cross validation\n",
        "\n",
        "For small datasets, a more accurate result can be achieved using cross validation. Scikit-learn has several convenience methods like `sklearn.model_selection.KFold`, or even better `sklearn.model_selection.StratifiedKFold`.\n",
        "\n",
        "Create a 5-fold cross validation object and use a for loop to repeak the above experiment, saving the results along for each fold. Finally provide the mean and standard devation of the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq5hwLIWzsEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQUeUYgfzsEy",
        "colab_type": "text"
      },
      "source": [
        "## ROC Curve\n",
        "\n",
        "The ROC Curve can be calculated only for binary problems. That is why we need a similar \"averageing\" method as with precision/recall. Furthermore, this method can be made more precise if we are given a probability instead of only a binary classification result. This allows us the set a threshold value based on the probability score.\n",
        "\n",
        "Retreain the logistic regression morel, but use `decision_funcion` instead of `predict` to get a more accurate result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9qcZL1PzsEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvwAPGzozsE1",
        "colab_type": "text"
      },
      "source": [
        "If we want to compare the result with reference labels, we first need to convert the rsult to binary. Use `sklearn.preprocessing.label_binarize`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joikvxNNzsE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-V9qkIYzsE3",
        "colab_type": "text"
      },
      "source": [
        "Now we can simply compute the ROC curve for any class using `sklearn.metrics.roc_curve` anc choosing a specific class from the array. This method returns 3 values, of which we need only the first to (FPR,TPR). Send them to the `plot` method, as well as to`sklearn.metrics.auc` to compute the area under the curve. Also draw a line between (0,0) and (1,1) to denote the random classification cutoff:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq9L3e_yzsE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohbdNWdmzsE6",
        "colab_type": "text"
      },
      "source": [
        "You can finally also draw the averaged plot for all classes (so called \"micro\" method) by using `ravel()` on the results and reference.\n",
        "\n",
        "More info about this: http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G3TH0xFzsE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fpr,tpr,_=sklearn.metrics.roc_curve(y_tst_bin.ravel(),h_tst.ravel())\n",
        "auc=sklearn.metrics.auc(fpr,tpr)\n",
        "plot(fpr,tpr)\n",
        "plot([0,1],[0,1],'k--')\n",
        "xlim(0,1)\n",
        "ylim(0,1.05)\n",
        "title('Krzywa ROC (AUC: {:%})'.format(auc))\n",
        "xlabel('False positive rate')\n",
        "ylabel('True positive rate')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSeEHgsAzsE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}