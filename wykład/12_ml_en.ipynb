{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        },
        "pycharm": {}
      },
      "source": "# Examples of signal processing applications\n## In machine learning"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "slideshow": {
          "slide_type": "slide"
        },
        "pycharm": {}
      },
      "source": "## Machine learning\n\n- Artificial intelligence (AI)\n    - rule-based\n    - data-driven\n- Machine learning problems\n    - classification\n    - regression\n    - clustering\n- Components of ML systems\n    - model\n    - fit (tune model parametrs to fit data)\n    - predict (inference, testing, evaluation)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        },
        "pycharm": {}
      },
      "source": "## Image recognition\n\n### Using the MNIST dataset as an example\n\n\u003cimg src\u003d\"images/mnist.png\" style\u003d\"width:200px\"\u003e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "pycharm": {}
      },
      "source": "### About the dataset\n\n- 60 000 images in train, 10 000 in test subset\n- 20x20 pixels in a 28x28 pixel image\n- http://yann.lecun.com/exdb/mnist/"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "pycharm": {}
      },
      "source": "### Experiment procedure\n\n1. dataset preparation\n    - split into train and test\n2. train model on train subset\n3. test model on test subset"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "pycharm": {}
      },
      "source": "### Experiemnt procedure\n#### Early stopping\n\n1. dataset preparation\n    - split into train, validation and test\n2. train model on train subset\n    - test on validation subset while training\n3. eventually test on test subset\n\t- use the model from the iteration where the result on validation was best"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "pycharm": {}
      },
      "source": "### Experiemnt procedure\n#### k-fold cross validation\n\n1. for each $k$ in $N$ equal subsets of the whole dataset \n    1. set $k$ subset as the test set and everything else as train\n    2. train on the train data\n    3. test on the test data    \n2. evaluation result is the mean of all $N$ experiments (so called \"folds\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "pycharm": {}
      },
      "source": "### Experiemnt procedure\n#### Leave one out\n\n1. for each sample in the dataset\n    1. set the chosen sample as the test set and everything else as train \n\t2. train on the train data\n    3. test on the test data    \n2. evaluation result is the mean of all above experiments"
    },
    {
      "cell_type": "markdown",
      "source": "### Evaluation measures\n\n- log-loss\n- accuracy\n- precision/recall/F1\n\n\u003ca href\u003d\"images/DiagnosticTesting Diagram.svg\"\u003e\u003cimg src\u003d\"images/DiagnosticTesting Diagram.svg\" style\u003d\"width: 500px\"\u003e\u003c/a\u003e",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "pycharm": {}
      },
      "source": "### ROC curve\n\n\u003cimg src\u003d\"images/ROC_space.png\" style\u003d\"width:500px\"\u003e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "pycharm": {}
      },
      "source": [
        "### Krzywa ROC\n",
        "\n",
        "- sensitivity vs (1-specificity)\n",
        "- AUC\n",
        "\n",
        "\u003cimg src\u003d\"images/roc.png\" style\u003d\"width:300px\"\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "pycharm": {}
      },
      "source": [
        "### Confusion matrix\n",
        "\n",
        "![](images/confusion.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        },
        "pycharm": {}
      },
      "source": "## CIFAR dataset\n\n\n- https://www.cs.toronto.edu/~kriz/cifar.html\n\n![](images/cifar-10.png)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "pycharm": {}
      },
      "source": "## Bag of Visual Words model\n\n- BoW model for document (article) classification\n- image feature set\n    - eg. SIFT\n- grouping features\n    - clustering\n- classification"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "pycharm": {}
      },
      "source": [
        "![](images/bovw_visual_word_counts.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "pycharm": {}
      },
      "source": "## Convolution networks\n\n\n![](images/imagenet_vgg16.png)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        },
        "pycharm": {}
      },
      "source": "## Speech recognition\n\n- audio -\u003e text\n- complex procedure:\n    - feature extraction\n    - speech detection\n    - speaker recognition\n    - acoustic modeling\n    - G2P conversion\n    - language modeling\n    - speech decoding"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "pycharm": {}
      },
      "source": "## Hearing\n\n![](images/ear.jpg)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "pycharm": {}
      },
      "source": "## Speech organs\n\n\u003cimg src\u003d\"images/Sagittalmouth.png\" style\u003d\"width:300px\"\u003e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        },
        "pycharm": {}
      },
      "source": "## Feature extraction procedure\n\nhttps://github.com/danijel3/PyHTK/blob/master/python-notebooks/HTKFeaturesExplained.ipynb"
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}