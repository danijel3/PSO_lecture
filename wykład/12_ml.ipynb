{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Przykłady zastosowania przetwarzania sygnałów\n",
    "## W maszynowym uczeniu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Maszynowe Uczenie\n",
    "\n",
    "- Sztuczna Inteligencja (AI)\n",
    "    - systemy regułowe (*rule-based*)\n",
    "    - uczone na danych (*data-driven*)\n",
    "- Problemy uczenia maszynowego (*machine learning*)\n",
    "    - klasyfikacja\n",
    "    - regresja\n",
    "    - analiza skupień (clustering)\n",
    "- Składowe systemu ML\n",
    "    - model\n",
    "    - dopasowanie (trenowanie, *fit*)\n",
    "    - predykcja (testowanie, ewaluacja)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Rozpoznawanie obrazów\n",
    "\n",
    "### Na przykładzie bazy MNIST\n",
    "\n",
    "<img src=\"images/mnist.png\" style=\"width:200px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### O zbiorze\n",
    "\n",
    "- 60 000 obrazków w zbiorze train, 10 000 w test\n",
    "- 20x20 pikseli w obrazie 28x28\n",
    "- http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Procedura eksperymentalna\n",
    "\n",
    "1. przygotowanie zbioru danych\n",
    "    - podział na treningowy i testowy\n",
    "2. trenowanie modelu na zbiorze treningowym\n",
    "3. testowanie na zbiorze testowym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Procedura eksperymentalna\n",
    "#### Early stopping\n",
    "\n",
    "1. przygotowanie zbioru danych\n",
    "    - podział na treningowy, walidacyjny i testowy\n",
    "2. trenowanie modelu na zbiorze treningowym\n",
    "    - testowanie na zbiorze walidacyjnym\n",
    "3. testowanie na zbiorze testowym\n",
    "    - używając modelu z iteracji w którym wynik na zbiorze walidacyjnym był najlepszy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Procedura eksperymentalna\n",
    "#### Walidacja krzyżowa (*k-fold cross validation*)\n",
    "\n",
    "1. dla każdego $k$ z $N$ podzbiorów całego zbioru danych\n",
    "    1. ustaw że $k$ to zbiór testowy, a wszysztko inne to zbiór treningowy\n",
    "    2. trenowanie modelu na zbiorze treningowym\n",
    "    3. testowanie na zbiorze testowym    \n",
    "2. wynik ewaluacji to średnia z poszczególnych testów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Procedura eksperymentalna\n",
    "#### *Leave one out*\n",
    "\n",
    "1. dla każdej próbki ze zbioru danych\n",
    "    1. ustaw że bieżąca próbka to zbiór testowy, a wszysztko inne to zbiór treningowy\n",
    "    2. trenowanie modelu na zbiorze treningowym\n",
    "    3. testowanie na zbiorze testowym    \n",
    "2. wynik ewaluacji to średnia z poszczególnych testów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Miary ewaluacji\n",
    "\n",
    "- log-loss\n",
    "- accuracy\n",
    "- precision/recall/F1\n",
    "\n",
    "<a href=\"images/DiagnosticTesting Diagram.svg\"><img src=\"images/DiagnosticTesting Diagram.svg\" style=\"width: 500px\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Krzywa ROC\n",
    "\n",
    "<img src=\"images/ROC_space.png\" style=\"width:500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Krzywa ROC\n",
    "\n",
    "- sensitivity vs (1-specificity)\n",
    "- AUC\n",
    "\n",
    "<img src=\"images/roc.png\" style=\"width:300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Confusion matrix\n",
    "\n",
    "![](images/confusion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Zbiór CIFAR\n",
    "\n",
    "\n",
    "- https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "![](images/cifar-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Model Bag of Visual Words\n",
    "\n",
    "- model BOW do klasyfikacji dokumentów\n",
    "- zestaw cech obrazów\n",
    "    - SIFT\n",
    "- kategoryzacja cech\n",
    "    - clustering\n",
    "- klasyfikacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](images/bovw_visual_word_counts.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sieci splotowe\n",
    "\n",
    "\n",
    "![](images/imagenet_vgg16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Rozpoznawanie mowy\n",
    "\n",
    "- audio -> tekst\n",
    "- złożona procedura:\n",
    "    - ekstrakcja cech\n",
    "    - detekcja mowy\n",
    "    - detekcja mówcy\n",
    "    - modelowanie akustyczne\n",
    "    - konwersja G2P\n",
    "    - modelowanie języka\n",
    "    - dekodowanie wypowiedzi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Słuch\n",
    "\n",
    "![](images/ear.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Aparat mowy\n",
    "\n",
    "<img src=\"images/Sagittalmouth.png\" style=\"width:300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Procedura ekstrakcji cech\n",
    "\n",
    "https://github.com/danijel3/PyHTK/blob/master/python-notebooks/HTKFeaturesExplained.ipynb"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
